{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41eaccd8-e3c7-4f3b-8512-0e45a13d49a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Conv2D, Input, Lambda, LeakyReLU, MaxPool2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import binary_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import emergency_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1dac873c-de97-433c-b202-1b9aedc4efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHORS = np.array([\n",
    "    (10,13), (16,30), (33,23), (30,61), (62,45),\n",
    "    (59,119), (116,90), (156,198), (373,326)], np.float32) / 416\n",
    "\n",
    "MASKS = np.array([\n",
    "    [6,7,8], [3,4,5], [0,1,2]])\n",
    "\n",
    "LAYERS = [\n",
    "    'yolo_darknet',\n",
    "    'yolo_conv_0',\n",
    "    'yolo_output_0',\n",
    "    'yolo_conv_1',\n",
    "    'yolo_output_1',\n",
    "    'yolo_conv_2',\n",
    "    'yolo_output_2'\n",
    "]\n",
    "\n",
    "SIZE = 416\n",
    "CLASSES = 1\n",
    "LR = 1e-5\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b0c2cb6-4b6b-436d-b81d-b6c52e2cb120",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1,0), (1,0)))(x)\n",
    "        padding = 'valid'\n",
    "    x = Conv2D(filters, size, strides, padding, use_bias= not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "    return x\n",
    "\n",
    "def DarknetRes(x, filters):\n",
    "    skip = x\n",
    "    x = DarknetConv(x, filters // 2, 1)\n",
    "    x = DarknetConv(x, filters, 3)\n",
    "    x = Add()([skip, x])\n",
    "    return x\n",
    "\n",
    "def DarknetBlock(x, filters, blocks):\n",
    "    x = DarknetConv(x, filters, 3, 2)\n",
    "    for _ in range(blocks):\n",
    "        x = DarknetRes(x, filters)\n",
    "    return x\n",
    "\n",
    "def Darknet(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = DarknetBlock(x, 64, 1)\n",
    "    x = DarknetBlock(x, 128, 2)\n",
    "    x = out1 = DarknetBlock(x, 256, 8)\n",
    "    x = out2 = DarknetBlock(x, 512, 8)\n",
    "    x = out3 = DarknetBlock(x, 1024, 4)\n",
    "    return Model(inputs, (out1, out2, out3), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3876669-e610-4573-bdbe-015c0a66caf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloConv(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "        \n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, filters, 1)\n",
    "        \n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv\n",
    "\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x : tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2], anchors, classes + 5)))(x)\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "65c862c8-3511-4cbe-bcb4-e58147dc7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes(pred, anchors, classes):\n",
    "    \n",
    "    grid_size = tf.shape(pred)[1:3]\n",
    "    \n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(pred, (2,2,1,classes), axis=-1)\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "    \n",
    "    grid = tf.meshgrid(tf.range(grid_size[1]), tf.range(grid_size[0]))\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "    \n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "    \n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "    \n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "    \n",
    "    b,c,t = [],[],[]\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "    \n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "    \n",
    "    if classes == 1:\n",
    "        scores = confidence\n",
    "    else:\n",
    "        scores = confidence * class_probs\n",
    "    \n",
    "    dscores = tf.squeeze(scores, axis=0)\n",
    "    scores = tf.reduce_max(dscores, [1])\n",
    "    bbox = tf.reshape(bbox, (-1, 4))\n",
    "    classes = tf.argmax(dscores, 1)\n",
    "    selected_indices, selected_scores = tf.image.non_max_suppression_with_scores(\n",
    "        boxes=bbox,\n",
    "        scores=scores,\n",
    "        max_output_size=100,\n",
    "        iou_threshold=0.5,\n",
    "        score_threshold=0.5,\n",
    "        soft_nms_sigma=0.5\n",
    "    )\n",
    "    \n",
    "    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n",
    "    selected_indices = tf.concat([selected_indices, tf.zeros(100 - num_valid_nms_boxes, tf.int32)], 0)\n",
    "    selected_scores = tf.concat([selected_scores, tf.zeros(100 - num_valid_nms_boxes, tf.float32)], -1)\n",
    "    \n",
    "    boxes = tf.gather(bbox, selected_indices)\n",
    "    boxes = tf.expand_dims(boxes, axis=0)\n",
    "    scores = selected_scores\n",
    "    scores = tf.expand_dims(scores, axis=0)\n",
    "    classes = tf.gather(classes, selected_indices)\n",
    "    classes = tf.expand_dims(classes, axis=0)\n",
    "    valid_detections = num_valid_nms_boxes\n",
    "    valid_detections = tf.expand_dims(valid_detections, axis=0)\n",
    "    \n",
    "    return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2e611505-7c2a-48f1-b6c2-18907ee3d441",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Yolo(size=None, channels=3, anchors=ANCHORS, masks=MASKS, classes=CLASSES, training=False):\n",
    "    \n",
    "    x = inputs = Input([size, size, channels], name=\"image\")\n",
    "    x36, x61, x = Darknet(name=\"yolo_darknet\")(x)\n",
    "    \n",
    "    x = YoloConv(512, name=\"yolo_conv_0\")(x)\n",
    "    output0 = YoloOutput(512, len(masks[0]), classes, name=\"yolo_output_0\")(x)\n",
    "    \n",
    "    x = YoloConv(256, name=\"yolo_conv_1\")((x, x61))\n",
    "    output1 = YoloOutput(256, len(masks[1]), classes, name=\"yolo_output_1\")(x)\n",
    "\n",
    "    x = YoloConv(128, name=\"yolo_conv_2\")((x, x36))\n",
    "    output2 = YoloOutput(128, len(masks[2]), classes, name=\"yolo_output_2\")(x)\n",
    "    \n",
    "    if training:\n",
    "        return Model(inputs, (output0, output1, output2), name=\"yolov3\")\n",
    "    \n",
    "    boxes0 = Lambda(lambda x : yolo_boxes(x, anchors[masks[0]], classes), name=\"yolo_boxes_0\")(output0)\n",
    "    boxes1 = Lambda(lambda x : yolo_boxes(x, anchors[masks[1]], classes), name=\"yolo_boxes_1\")(output1)\n",
    "    boxes2 = Lambda(lambda x : yolo_boxes(x, anchors[masks[2]], classes), name=\"yolo_boxes_2\")(output2)\n",
    "    outputs = Lambda(lambda x : yolo_nms(x, anchors, masks, classes), name=\"yolo_nms\")((boxes0[:3], boxes1[:3], boxes2[:3]))\n",
    "    \n",
    "    return Model(inputs, outputs, name='yolov3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "00462714-550d-467f-9633-086e6e5e3685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box1, box2):\n",
    "    box1 = tf.expand_dims(box1, -2)\n",
    "    box2 = tf.expand_dims(box2, 0)\n",
    "    \n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box1), tf.shape(box2))\n",
    "    box1 = tf.broadcast_to(box1, new_shape)\n",
    "    box2 = tf.broadcast_to(box2, new_shape)\n",
    "    \n",
    "    int_w = tf.maximum(tf.minimum(box1[..., 2], box2[..., 2]) - tf.maximum(box1[..., 0], box2[..., 0]), 0)\n",
    "    int_h = tf.maximum(tf.minimum(box1[..., 3], box2[..., 3]) - tf.maximum(box1[..., 1], box2[..., 1]), 0)\n",
    "    int_area = int_w * int_h\n",
    "    \n",
    "    box1_area = (box1[..., 2] - box1[..., 0]) * (box1[..., 3] - box1[..., 1])\n",
    "    box2_area = (box2[..., 2] - box2[..., 0]) * (box2[..., 3] - box2[..., 1])\n",
    "    \n",
    "    return int_area / (box1_area + box2_area - int_area)\n",
    "\n",
    "def YoloLoss(anchors, classes=CLASSES, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        \n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "        \n",
    "        true_box, true_obj, true_class_idx = tf.split(y_true, (4,1,1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "        \n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "        \n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        best_iou = tf.map_fn(lambda x : tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(x[1], tf.cast(x[2], tf.bool))), axis=-1), (pred_box, true_box, obj_mask), tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        \n",
    "        xy_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(true_class_idx, pred_class)\n",
    "        \n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1,2,3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1,2,3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1,2,3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1,2,3))\n",
    "        \n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return yolo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5d600510-22d8-44c9-9111-b098833201f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_darknet_weigths(weight_file, output_file):\n",
    "    \n",
    "    model = Yolo()\n",
    "    \n",
    "    wf = open(weight_file, 'rb')\n",
    "    _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "    \n",
    "    for layer_name in LAYERS:\n",
    "        submodel = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(submodel.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            \n",
    "            batch_norm = None\n",
    "            if i + 1 < len(submodel.layers) and submodel.layers[i+1].name.startswith('batch_norm'):\n",
    "                batch_norm = submodel.layers[i+1]\n",
    "            \n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.get_input_shape_at(0)[-1]\n",
    "            \n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                bn_weights = np.fromfile(wf, dtype=np.float32, count = 4*filters)\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1,0,2,3]]\n",
    "            \n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            conv_weights = conv_weights.reshape(conv_shape).transpose([2,3,1,0])\n",
    "            \n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "        \n",
    "    wf.close()\n",
    "    \n",
    "    test = np.random.random((1,320,320,3)).astype(np.float32)\n",
    "    testout = model(test)\n",
    "    \n",
    "    model.save_weights(output_file)\n",
    "\n",
    "def draw_outputs(img, outputs):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255,0,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "61c6d713-f82c-43be-9973-e0e6ca0e9bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(im, size):\n",
    "    return tf.image.resize(im, (size, size)) / 255\n",
    "\n",
    "@tf.function\n",
    "def transform_labels_for_output(label, grid_size, anchor_idxs):\n",
    "    \n",
    "    N = tf.shape(label)[0]\n",
    "    y_out = tf.zeros((N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "    \n",
    "    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "    \n",
    "    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "    \n",
    "    idx = 0\n",
    "    for i in tf.range(N):\n",
    "        for j in tf.range(tf.shape(label)[1]):\n",
    "            if tf.equal(label[i][j][2], 0):\n",
    "                continue\n",
    "            \n",
    "            anchor_eq = tf.equal(anchor_idxs, tf.cast(label[i][j][5], tf.int32))\n",
    "            if tf.reduce_any(anchor_eq):\n",
    "                box = label[i][j][0:4]\n",
    "                box_xy = (label[i][j][0:2] + label[i][j][2:4]) / 2\n",
    "                \n",
    "                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\n",
    "                \n",
    "                indexes = indexes.write(idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "                updates = updates.write(idx, [box[0], box[1], box[2], box[3], 1, label[i][j][4]])\n",
    "                \n",
    "                idx += 1\n",
    "    \n",
    "    return tf.tensor_scatter_nd_update(y_out, indexes.stack(), updates.stack())\n",
    "                \n",
    "\n",
    "def transform_labels(label, size):\n",
    "    \n",
    "    # reorder, format label\n",
    "    c = tf.expand_dims(label[..., 0], axis=-1)\n",
    "    x1y1 = label[..., 1:3] - label[..., 3:5] / 2\n",
    "    x2y2 = label[..., 1:3] + label[..., 3:5] / 2\n",
    "    label = tf.concat((x1y1, x2y2, c), axis=-1)\n",
    "    \n",
    "    y_outs = []\n",
    "    grid_size = size // 32\n",
    "    \n",
    "    anchors = tf.cast(ANCHORS, tf.float32)\n",
    "    anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "    \n",
    "    box_wh = label[..., 2:4] - label[..., 0:2]\n",
    "    box_wh = tf.tile(tf.expand_dims(box_wh, -2), (1, 1, tf.shape(anchors)[0], 1))\n",
    "    box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "    \n",
    "    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * tf.minimum(box_wh[..., 1], anchors[..., 1])\n",
    "    iou = intersection / (box_area + anchor_area - intersection)\n",
    "    \n",
    "    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "    \n",
    "    label = tf.concat([label, anchor_idx], axis=-1)\n",
    "    \n",
    "    for anchor_idxs in MASKS:\n",
    "        y_outs.append(transform_labels_for_output(label, grid_size, anchor_idxs))\n",
    "        grid_size *= 2\n",
    "    \n",
    "    return tuple(y_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92dd8bf7-9ed9-4010-8db3-55bd041a9ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_freeze(model):\n",
    "    model.trainable = False\n",
    "    if isinstance(model, Model):\n",
    "        for layer in model.layers:\n",
    "            recursive_freeze(layer)\n",
    "\n",
    "def setup():\n",
    "    \n",
    "    model = Yolo(size=SIZE, training=True)\n",
    "    \n",
    "    model_pretrained = Yolo(size=SIZE, training=True, classes=80)\n",
    "    model_pretrained.load_weights(\"./yolov3.tf\")\n",
    "    model.get_layer(\"yolo_darknet\").set_weights(model_pretrained.get_layer(\"yolo_darknet\").get_weights())\n",
    "    recursive_freeze(model.get_layer(\"yolo_darknet\"))\n",
    "    \n",
    "    optimizer = Adam(lr=LR)\n",
    "    loss = [YoloLoss(ANCHORS[mask]) for mask in MASKS]\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    return model, optimizer, loss\n",
    "\n",
    "def train(chk=0):\n",
    "    \n",
    "    if chk == 0:\n",
    "        model, optimizer, loss = setup()\n",
    "    else:\n",
    "        model = Yolo(size=SIZE, training=True)\n",
    "        model.load_weights(\"./checkpoints/train_\" + str(chk) + \".tf\")\n",
    "        recursive_freeze(model.get_layer(\"yolo_darknet\"))\n",
    "        optimizer = Adam(learning_rate=LR)\n",
    "        loss = [YoloLoss(ANCHORS[mask]) for mask in MASKS]\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    train_dataset = tfds.load(\"emergency_dataset\", split='train', as_supervised=True)\n",
    "    train_dataset = train_dataset.shuffle(1000)\n",
    "    train_dataset = train_dataset.batch(8)\n",
    "    #train_dataset = train_dataset.map(lambda x: {\"image\" : transform_images(x[\"image\"], 416), \"label\" : transform_labels(x[\"label\"], 416)})\n",
    "    train_dataset = train_dataset.map(lambda x, y : (transform_images(x, 416), transform_labels(y, 416)))\n",
    "    \n",
    "    val_dataset = tfds.load(\"emergency_dataset\", split='val', as_supervised=True)\n",
    "    val_dataset = val_dataset.shuffle(1000)\n",
    "    val_dataset = val_dataset.batch(8)\n",
    "    #val_dataset = val_dataset.map(lambda x: {\"image\" : transform_images(x[\"image\"], 416), \"label\" : transform_labels(x[\"label\"], 416)})\n",
    "    val_dataset = val_dataset.map(lambda x, y : (transform_images(x, 416), transform_labels(y, 416)))\n",
    "    \n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(verbose=1),\n",
    "        #EarlyStopping(patience=3, verbose=1),\n",
    "        ModelCheckpoint('./checkpoints/train_{epoch}.tf', verbose=1, save_weights_only=True),\n",
    "        TensorBoard(log_dir='logs')\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719fe61f-78dd-4310-bd0b-64e254c54b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(chk=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "db539e7b-daa0-4eba-87e6-3b19745ab84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x1c0080bfb50>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Yolo(training=False)\n",
    "model.load_weights(\"./checkpoints/train_20.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "79ef9bf5-f023-4d46-b7eb-736864b06a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\"emergency_dataset\", split=\"val\")\n",
    "ds = ds.batch(1)\n",
    "ds = ds.shuffle(1000)\n",
    "ds = ds.take(1)\n",
    "im = 1\n",
    "for e in ds:\n",
    "    im = e['image']\n",
    "imraw = im\n",
    "im = transform_images(im, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "82f30b66-248b-4753-85b3-074e16029a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([0.33476877 0.36452606 0.6444214  0.5846996 ], shape=(4,), dtype=float32) tf.Tensor(0.65301704, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "boxes, scores, classes, nums = model(im)\n",
    "print(boxes[0,0], scores[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "59343ee3-de75-4812-8df9-0475bebb6bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img = cv2.cvtColor(np.squeeze(imraw.numpy(), 0), cv2.COLOR_RGB2BGR)\n",
    "img = draw_outputs(img, (boxes, scores, classes, nums))\n",
    "cv2.imshow(\"a\", img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "72dbd69e-89b2-45a7-8003-aea087bb0bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cv2.imwrite(\"./examplebad.jpg\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a43a7ab-54b6-4fc8-8730-5393120a0163",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fd44b8-bfe5-4943-8e5e-534d887c1eda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4597d1f-4028-4ebd-b499-47f1895ed3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tflite(inpath, outpath):\n",
    "    model = Yolo(size=SIZE)\n",
    "    model.load_weights(inpath)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.experimental_new_converter = True\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    tflite_model = converter.convert()\n",
    "    f = open(outpath, 'wb')\n",
    "    f.write(tflite_model)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb14dba-7a81-41c8-836b-79f9ba8a40c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_tflite(\"./checkpoints/train_20.tf\", \"./models/yolo.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22aadd59-6cd8-4227-9087-da7669325fcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
