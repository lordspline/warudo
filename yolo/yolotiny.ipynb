{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "092935d4-f5d8-414e-bc5c-9d0bab0317a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Add, Concatenate, Conv2D, Input, Lambda, LeakyReLU, MaxPool2D, UpSampling2D, ZeroPadding2D, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.losses import binary_crossentropy, sparse_categorical_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "\n",
    "import tensorflow_datasets as tfds\n",
    "import emergency_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f591ea5a-8f49-4684-8f87-baee765fea5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHORS = np.array([\n",
    "    (10, 14), (23, 27), (37, 58),\n",
    "    (81, 82), (135, 169),  (344, 319)], np.float32) / 416\n",
    "\n",
    "MASKS = np.array([[3, 4, 5], [0, 1, 2]])\n",
    "\n",
    "LAYERS = [\n",
    "    'yolo_darknet',\n",
    "    'yolo_conv_0',\n",
    "    'yolo_output_0',\n",
    "    'yolo_conv_1',\n",
    "    'yolo_output_1',\n",
    "]\n",
    "\n",
    "SIZE = 416\n",
    "CLASSES = 1\n",
    "LR = 1e-4\n",
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49c57c18-1405-418e-a519-537a5b2f4a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DarknetConv(x, filters, size, strides=1, batch_norm=True):\n",
    "    if strides == 1:\n",
    "        padding = 'same'\n",
    "    else:\n",
    "        x = ZeroPadding2D(((1,0), (1,0)))(x)\n",
    "        padding = 'valid'\n",
    "    x = Conv2D(filters, size, strides, padding, use_bias= not batch_norm, kernel_regularizer=l2(0.0005))(x)\n",
    "    if batch_norm:\n",
    "        x = BatchNormalization()(x)\n",
    "        x = LeakyReLU(0.1)(x)\n",
    "    return x\n",
    "\n",
    "def DarknetTiny(name=None):\n",
    "    x = inputs = Input([None, None, 3])\n",
    "    x = DarknetConv(x, 16, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 32, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 64, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 128, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = x_8 = DarknetConv(x, 256, 3)\n",
    "    x = MaxPool2D(2, 2, 'same')(x)\n",
    "    x = DarknetConv(x, 512, 3)\n",
    "    x = MaxPool2D(2, 1, 'same')(x)\n",
    "    x = DarknetConv(x, 1024, 3)\n",
    "    return tf.keras.Model(inputs, (x_8, x), name=name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6a5c1806-7b0e-4f7c-a4a0-57433cceeb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloConvTiny(filters, name=None):\n",
    "    def yolo_conv(x_in):\n",
    "        if isinstance(x_in, tuple):\n",
    "            inputs = Input(x_in[0].shape[1:]), Input(x_in[1].shape[1:])\n",
    "            x, x_skip = inputs\n",
    "\n",
    "            # concat with skip connection\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "            x = UpSampling2D(2)(x)\n",
    "            x = Concatenate()([x, x_skip])\n",
    "        else:\n",
    "            x = inputs = Input(x_in.shape[1:])\n",
    "            x = DarknetConv(x, filters, 1)\n",
    "\n",
    "        return Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_conv\n",
    "\n",
    "def YoloOutput(filters, anchors, classes, name=None):\n",
    "    def yolo_output(x_in):\n",
    "        x = inputs = Input(x_in.shape[1:])\n",
    "        x = DarknetConv(x, filters * 2, 3)\n",
    "        x = DarknetConv(x, anchors * (classes + 5), 1, batch_norm=False)\n",
    "        x = Lambda(lambda x: tf.reshape(x, (-1, tf.shape(x)[1], tf.shape(x)[2],\n",
    "                                            anchors, classes + 5)))(x)\n",
    "        return tf.keras.Model(inputs, x, name=name)(x_in)\n",
    "    return yolo_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a242c890-2f4c-4ebc-a571-366fd03f4058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _meshgrid(n_a, n_b):\n",
    "    return [\n",
    "        tf.reshape(tf.tile(tf.range(n_a), [n_b]), (n_b, n_a)),\n",
    "        tf.reshape(tf.repeat(tf.range(n_b), n_a), (n_b, n_a))\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06c4bd38-2673-4be1-becf-5b72003c2e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_boxes(pred, anchors, classes):\n",
    "    \n",
    "    grid_size = tf.shape(pred)[1:3]\n",
    "    \n",
    "    box_xy, box_wh, objectness, class_probs = tf.split(pred, (2,2,1,classes), axis=-1)\n",
    "    box_xy = tf.sigmoid(box_xy)\n",
    "    objectness = tf.sigmoid(objectness)\n",
    "    class_probs = tf.sigmoid(class_probs)\n",
    "    pred_box = tf.concat((box_xy, box_wh), axis=-1)\n",
    "    \n",
    "    grid = _meshgrid(grid_size[1], grid_size[0])\n",
    "    grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "    \n",
    "    box_xy = (box_xy + tf.cast(grid, tf.float32)) / tf.cast(grid_size, tf.float32)\n",
    "    box_wh = tf.exp(box_wh) * anchors\n",
    "    \n",
    "    box_x1y1 = box_xy - box_wh / 2\n",
    "    box_x2y2 = box_xy + box_wh / 2\n",
    "    bbox = tf.concat([box_x1y1, box_x2y2], axis=-1)\n",
    "    \n",
    "    return bbox, objectness, class_probs, pred_box\n",
    "\n",
    "def yolo_nms(outputs, anchors, masks, classes):\n",
    "    \n",
    "    b,c,t = [],[],[]\n",
    "    for o in outputs:\n",
    "        b.append(tf.reshape(o[0], (tf.shape(o[0])[0], -1, tf.shape(o[0])[-1])))\n",
    "        c.append(tf.reshape(o[1], (tf.shape(o[1])[0], -1, tf.shape(o[1])[-1])))\n",
    "        t.append(tf.reshape(o[2], (tf.shape(o[2])[0], -1, tf.shape(o[2])[-1])))\n",
    "    \n",
    "    bbox = tf.concat(b, axis=1)\n",
    "    confidence = tf.concat(c, axis=1)\n",
    "    class_probs = tf.concat(t, axis=1)\n",
    "    \n",
    "    if classes == 1:\n",
    "        scores = confidence\n",
    "    else:\n",
    "        scores = confidence * class_probs\n",
    "    \n",
    "    dscores = tf.squeeze(scores, axis=0)\n",
    "    scores = tf.reduce_max(dscores, [1])\n",
    "    bbox = tf.reshape(bbox, (-1, 4))\n",
    "    classes = tf.argmax(dscores, 1)\n",
    "    selected_indices, selected_scores = tf.image.non_max_suppression_with_scores(\n",
    "        boxes=bbox,\n",
    "        scores=scores,\n",
    "        max_output_size=100,\n",
    "        iou_threshold=0.5,\n",
    "        score_threshold=0.5,\n",
    "        soft_nms_sigma=0.5\n",
    "    )\n",
    "    \n",
    "    num_valid_nms_boxes = tf.shape(selected_indices)[0]\n",
    "    selected_indices = tf.concat([selected_indices, tf.zeros(100 - num_valid_nms_boxes, tf.int32)], 0)\n",
    "    selected_scores = tf.concat([selected_scores, tf.zeros(100 - num_valid_nms_boxes, tf.float32)], -1)\n",
    "    \n",
    "    boxes = tf.gather(bbox, selected_indices)\n",
    "    boxes = tf.expand_dims(boxes, axis=0)\n",
    "    scores = selected_scores\n",
    "    scores = tf.expand_dims(scores, axis=0)\n",
    "    classes = tf.gather(classes, selected_indices)\n",
    "    classes = tf.expand_dims(classes, axis=0)\n",
    "    valid_detections = num_valid_nms_boxes\n",
    "    valid_detections = tf.expand_dims(valid_detections, axis=0)\n",
    "    \n",
    "    return boxes, scores, classes, valid_detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee8ff2c0-7a61-4a2c-9727-3f36255d07db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YoloTiny(size=None, channels=3, anchors=ANCHORS, masks=MASKS, classes=CLASSES, training=False):\n",
    "    x = inputs = Input([size, size, channels], name='input')\n",
    "\n",
    "    x_8, x = DarknetTiny(name='yolo_darknet')(x)\n",
    "\n",
    "    x = YoloConvTiny(256, name='yolo_conv_0')(x)\n",
    "    output_0 = YoloOutput(256, len(masks[0]), classes, name='yolo_output_0')(x)\n",
    "    \n",
    "    x = YoloConvTiny(128, name='yolo_conv_1')((x, x_8))\n",
    "    output_1 = YoloOutput(128, len(masks[1]), classes, name='yolo_output_1')(x)\n",
    "\n",
    "    if training:\n",
    "        return Model(inputs, (output_0, output_1), name='yolov3')\n",
    "\n",
    "    boxes_0 = Lambda(lambda x: yolo_boxes(x, anchors[masks[0]], classes),\n",
    "                     name='yolo_boxes_0')(output_0)\n",
    "    boxes_1 = Lambda(lambda x: yolo_boxes(x, anchors[masks[1]], classes),\n",
    "                     name='yolo_boxes_1')(output_1)\n",
    "    outputs = Lambda(lambda x: yolo_nms(x, anchors, masks, classes),\n",
    "                     name='yolo_nms')((boxes_0[:3], boxes_1[:3]))\n",
    "    return Model(inputs, outputs, name='yolov3_tiny')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3034c6d5-bcac-43b6-9912-84ad5fe2f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def broadcast_iou(box1, box2):\n",
    "    box1 = tf.expand_dims(box1, -2)\n",
    "    box2 = tf.expand_dims(box2, 0)\n",
    "    \n",
    "    new_shape = tf.broadcast_dynamic_shape(tf.shape(box1), tf.shape(box2))\n",
    "    box1 = tf.broadcast_to(box1, new_shape)\n",
    "    box2 = tf.broadcast_to(box2, new_shape)\n",
    "    \n",
    "    int_w = tf.maximum(tf.minimum(box1[..., 2], box2[..., 2]) - tf.maximum(box1[..., 0], box2[..., 0]), 0)\n",
    "    int_h = tf.maximum(tf.minimum(box1[..., 3], box2[..., 3]) - tf.maximum(box1[..., 1], box2[..., 1]), 0)\n",
    "    int_area = int_w * int_h\n",
    "    \n",
    "    box1_area = (box1[..., 2] - box1[..., 0]) * (box1[..., 3] - box1[..., 1])\n",
    "    box2_area = (box2[..., 2] - box2[..., 0]) * (box2[..., 3] - box2[..., 1])\n",
    "    \n",
    "    return int_area / (box1_area + box2_area - int_area)\n",
    "\n",
    "def YoloLoss(anchors, classes=CLASSES, ignore_thresh=0.5):\n",
    "    def yolo_loss(y_true, y_pred):\n",
    "        \n",
    "        pred_box, pred_obj, pred_class, pred_xywh = yolo_boxes(y_pred, anchors, classes)\n",
    "        pred_xy = pred_xywh[..., 0:2]\n",
    "        pred_wh = pred_xywh[..., 2:4]\n",
    "        \n",
    "        true_box, true_obj, true_class_idx = tf.split(y_true, (4,1,1), axis=-1)\n",
    "        true_xy = (true_box[..., 0:2] + true_box[..., 2:4]) / 2\n",
    "        true_wh = true_box[..., 2:4] - true_box[..., 0:2]\n",
    "        box_loss_scale = 2 - true_wh[..., 0] * true_wh[..., 1]\n",
    "        \n",
    "        grid_size = tf.shape(y_true)[1]\n",
    "        grid = tf.meshgrid(tf.range(grid_size), tf.range(grid_size))\n",
    "        grid = tf.expand_dims(tf.stack(grid, axis=-1), axis=2)\n",
    "        true_xy = true_xy * tf.cast(grid_size, tf.float32) - tf.cast(grid, tf.float32)\n",
    "        true_wh = tf.math.log(true_wh / anchors)\n",
    "        true_wh = tf.where(tf.math.is_inf(true_wh), tf.zeros_like(true_wh), true_wh)\n",
    "        \n",
    "        obj_mask = tf.squeeze(true_obj, -1)\n",
    "        best_iou = tf.map_fn(lambda x : tf.reduce_max(broadcast_iou(x[0], tf.boolean_mask(x[1], tf.cast(x[2], tf.bool))), axis=-1), (pred_box, true_box, obj_mask), tf.float32)\n",
    "        ignore_mask = tf.cast(best_iou < ignore_thresh, tf.float32)\n",
    "        \n",
    "        xy_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_xy - pred_xy), axis=-1)\n",
    "        wh_loss = obj_mask * box_loss_scale * tf.reduce_sum(tf.square(true_wh - pred_wh), axis=-1)\n",
    "        obj_loss = binary_crossentropy(true_obj, pred_obj)\n",
    "        obj_loss = obj_mask * obj_loss + (1 - obj_mask) * ignore_mask * obj_loss\n",
    "        class_loss = obj_mask * sparse_categorical_crossentropy(true_class_idx, pred_class)\n",
    "        \n",
    "        xy_loss = tf.reduce_sum(xy_loss, axis=(1,2,3))\n",
    "        wh_loss = tf.reduce_sum(wh_loss, axis=(1,2,3))\n",
    "        obj_loss = tf.reduce_sum(obj_loss, axis=(1,2,3))\n",
    "        class_loss = tf.reduce_sum(class_loss, axis=(1,2,3))\n",
    "        \n",
    "        return xy_loss + wh_loss + obj_loss + class_loss\n",
    "    return yolo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "427e52e6-24f3-447a-a1b8-9560a613a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_darknet_weigths(weight_file, output_file):\n",
    "    \n",
    "    model = YoloTiny(classes=80)\n",
    "    \n",
    "    wf = open(weight_file, 'rb')\n",
    "    _ = np.fromfile(wf, dtype=np.int32, count=5)\n",
    "    \n",
    "    for layer_name in LAYERS:\n",
    "        submodel = model.get_layer(layer_name)\n",
    "        for i, layer in enumerate(submodel.layers):\n",
    "            if not layer.name.startswith('conv2d'):\n",
    "                continue\n",
    "            \n",
    "            batch_norm = None\n",
    "            if i + 1 < len(submodel.layers) and submodel.layers[i+1].name.startswith('batch_norm'):\n",
    "                batch_norm = submodel.layers[i+1]\n",
    "            \n",
    "            filters = layer.filters\n",
    "            size = layer.kernel_size[0]\n",
    "            in_dim = layer.get_input_shape_at(0)[-1]\n",
    "            \n",
    "            if batch_norm is None:\n",
    "                conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n",
    "            else:\n",
    "                bn_weights = np.fromfile(wf, dtype=np.float32, count = 4*filters)\n",
    "                bn_weights = bn_weights.reshape((4, filters))[[1,0,2,3]]\n",
    "            \n",
    "            conv_shape = (filters, in_dim, size, size)\n",
    "            conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n",
    "            conv_weights = conv_weights.reshape(conv_shape).transpose([2,3,1,0])\n",
    "            \n",
    "            if batch_norm is None:\n",
    "                layer.set_weights([conv_weights, conv_bias])\n",
    "            else:\n",
    "                layer.set_weights([conv_weights])\n",
    "                batch_norm.set_weights(bn_weights)\n",
    "        \n",
    "    wf.close()\n",
    "\n",
    "    model.save_weights(output_file)\n",
    "\n",
    "def draw_outputs(img, outputs):\n",
    "    boxes, objectness, classes, nums = outputs\n",
    "    boxes, objectness, classes, nums = boxes[0], objectness[0], classes[0], nums[0]\n",
    "    wh = np.flip(img.shape[0:2])\n",
    "    for i in range(nums):\n",
    "        if objectness[i] <= 0:\n",
    "            continue\n",
    "        x1y1 = tuple((np.array(boxes[i][0:2]) * wh).astype(np.int32))\n",
    "        x2y2 = tuple((np.array(boxes[i][2:4]) * wh).astype(np.int32))\n",
    "        img = cv2.rectangle(img, x1y1, x2y2, (255,0,0), 2)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c74f6676-f5a7-43b5-a99e-38bcaf5e7379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_images(im, size):\n",
    "    return tf.image.resize(im, (size, size)) / 255\n",
    "\n",
    "@tf.function\n",
    "def transform_labels_for_output(label, grid_size, anchor_idxs):\n",
    "    \n",
    "    N = tf.shape(label)[0]\n",
    "    y_out = tf.zeros((N, grid_size, grid_size, tf.shape(anchor_idxs)[0], 6))\n",
    "    \n",
    "    anchor_idxs = tf.cast(anchor_idxs, tf.int32)\n",
    "    \n",
    "    indexes = tf.TensorArray(tf.int32, 1, dynamic_size=True)\n",
    "    updates = tf.TensorArray(tf.float32, 1, dynamic_size=True)\n",
    "    \n",
    "    idx = 0\n",
    "    for i in tf.range(N):\n",
    "        for j in tf.range(tf.shape(label)[1]):\n",
    "            if tf.equal(label[i][j][2], 0):\n",
    "                continue\n",
    "            \n",
    "            anchor_eq = tf.equal(anchor_idxs, tf.cast(label[i][j][5], tf.int32))\n",
    "            if tf.reduce_any(anchor_eq):\n",
    "                box = label[i][j][0:4]\n",
    "                box_xy = (label[i][j][0:2] + label[i][j][2:4]) / 2\n",
    "                \n",
    "                anchor_idx = tf.cast(tf.where(anchor_eq), tf.int32)\n",
    "                grid_xy = tf.cast(box_xy // (1/grid_size), tf.int32)\n",
    "                \n",
    "                indexes = indexes.write(idx, [i, grid_xy[1], grid_xy[0], anchor_idx[0][0]])\n",
    "                updates = updates.write(idx, [box[0], box[1], box[2], box[3], 1, label[i][j][4]])\n",
    "                \n",
    "                idx += 1\n",
    "    \n",
    "    return tf.tensor_scatter_nd_update(y_out, indexes.stack(), updates.stack())\n",
    "                \n",
    "\n",
    "def transform_labels(label, size):\n",
    "    \n",
    "    # reorder, format label\n",
    "    c = tf.expand_dims(label[..., 0], axis=-1)\n",
    "    x1y1 = label[..., 1:3] - label[..., 3:5] / 2\n",
    "    x2y2 = label[..., 1:3] + label[..., 3:5] / 2\n",
    "    label = tf.concat((x1y1, x2y2, c), axis=-1)\n",
    "    \n",
    "    y_outs = []\n",
    "    grid_size = size // 32\n",
    "    \n",
    "    anchors = tf.cast(ANCHORS, tf.float32)\n",
    "    anchor_area = anchors[..., 0] * anchors[..., 1]\n",
    "    \n",
    "    box_wh = label[..., 2:4] - label[..., 0:2]\n",
    "    box_wh = tf.tile(tf.expand_dims(box_wh, -2), (1, 1, tf.shape(anchors)[0], 1))\n",
    "    box_area = box_wh[..., 0] * box_wh[..., 1]\n",
    "    \n",
    "    intersection = tf.minimum(box_wh[..., 0], anchors[..., 0]) * tf.minimum(box_wh[..., 1], anchors[..., 1])\n",
    "    iou = intersection / (box_area + anchor_area - intersection)\n",
    "    \n",
    "    anchor_idx = tf.cast(tf.argmax(iou, axis=-1), tf.float32)\n",
    "    anchor_idx = tf.expand_dims(anchor_idx, axis=-1)\n",
    "    \n",
    "    label = tf.concat([label, anchor_idx], axis=-1)\n",
    "    \n",
    "    for anchor_idxs in MASKS:\n",
    "        y_outs.append(transform_labels_for_output(label, grid_size, anchor_idxs))\n",
    "        grid_size *= 2\n",
    "    \n",
    "    return tuple(y_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f12ef98-eacc-4d25-b2e6-b7294d72377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_freeze(model):\n",
    "    model.trainable = False\n",
    "    if isinstance(model, Model):\n",
    "        for layer in model.layers:\n",
    "            recursive_freeze(layer)\n",
    "\n",
    "def setup():\n",
    "    \n",
    "    model = YoloTiny(size=SIZE, training=True)\n",
    "    \n",
    "    model_pretrained = YoloTiny(size=SIZE, training=True, classes=80)\n",
    "    model_pretrained.load_weights(\"./yolov3_tiny.tf\")\n",
    "    model.get_layer(\"yolo_darknet\").set_weights(model_pretrained.get_layer(\"yolo_darknet\").get_weights())\n",
    "    recursive_freeze(model.get_layer(\"yolo_darknet\"))\n",
    "    \n",
    "    optimizer = Adam(lr=LR)\n",
    "    loss = [YoloLoss(ANCHORS[mask]) for mask in MASKS]\n",
    "    \n",
    "    model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    return model, optimizer, loss\n",
    "\n",
    "def train(chk=0):\n",
    "    \n",
    "    if chk == 0:\n",
    "        model, optimizer, loss = setup()\n",
    "    else:\n",
    "        model = YoloTiny(size=SIZE, training=True)\n",
    "        model.load_weights(\"./checkpointsTiny/train_\" + str(chk) + \".tf\")\n",
    "        recursive_freeze(model.get_layer(\"yolo_darknet\"))\n",
    "        optimizer = Adam(learning_rate=LR)\n",
    "        loss = [YoloLoss(ANCHORS[mask]) for mask in MASKS]\n",
    "        model.compile(optimizer=optimizer, loss=loss)\n",
    "    \n",
    "    train_dataset = tfds.load(\"emergency_dataset\", split='train', as_supervised=True)\n",
    "    train_dataset = train_dataset.shuffle(1500)\n",
    "    train_dataset = train_dataset.batch(8)\n",
    "    #train_dataset = train_dataset.map(lambda x: {\"image\" : transform_images(x[\"image\"], 416), \"label\" : transform_labels(x[\"label\"], 416)})\n",
    "    train_dataset = train_dataset.map(lambda x, y : (transform_images(x, 416), transform_labels(y, 416)))\n",
    "    \n",
    "    val_dataset = tfds.load(\"emergency_dataset\", split='val', as_supervised=True)\n",
    "    val_dataset = val_dataset.shuffle(1500)\n",
    "    val_dataset = val_dataset.batch(8)\n",
    "    #val_dataset = val_dataset.map(lambda x: {\"image\" : transform_images(x[\"image\"], 416), \"label\" : transform_labels(x[\"label\"], 416)})\n",
    "    val_dataset = val_dataset.map(lambda x, y : (transform_images(x, 416), transform_labels(y, 416)))\n",
    "    \n",
    "    callbacks = [\n",
    "        ReduceLROnPlateau(verbose=1),\n",
    "        # EarlyStopping(patience=3, verbose=1),\n",
    "        ModelCheckpoint('./checkpointsTiny/train_{epoch}.tf', verbose=1, save_weights_only=True),\n",
    "        TensorBoard(log_dir='logs')\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(train_dataset,\n",
    "                        epochs=EPOCHS,\n",
    "                        callbacks=callbacks,\n",
    "                        validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c36c680-5257-4241-8242-bfab7d0f7e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python310\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super(Adam, self).__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Python310\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py:616: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "166/166 [==============================] - ETA: 0s - loss: 824.1954 - yolo_output_0_loss: 154.0258 - yolo_output_1_loss: 666.4576\n",
      "Epoch 1: saving model to ./checkpointsTiny\\train_1.tf\n",
      "166/166 [==============================] - 28s 65ms/step - loss: 824.1954 - yolo_output_0_loss: 154.0258 - yolo_output_1_loss: 666.4576 - val_loss: 780.6624 - val_yolo_output_0_loss: 87.8499 - val_yolo_output_1_loss: 689.1013 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 242.6472 - yolo_output_0_loss: 33.2781 - yolo_output_1_loss: 205.6585\n",
      "Epoch 2: saving model to ./checkpointsTiny\\train_2.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 241.9442 - yolo_output_0_loss: 33.1637 - yolo_output_1_loss: 205.0700 - val_loss: 190.5687 - val_yolo_output_0_loss: 28.3525 - val_yolo_output_1_loss: 158.5064 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 132.9498 - yolo_output_0_loss: 18.0509 - yolo_output_1_loss: 111.1895\n",
      "Epoch 3: saving model to ./checkpointsTiny\\train_3.tf\n",
      "166/166 [==============================] - 7s 40ms/step - loss: 132.7866 - yolo_output_0_loss: 18.0356 - yolo_output_1_loss: 111.0417 - val_loss: 115.8856 - val_yolo_output_0_loss: 17.6436 - val_yolo_output_1_loss: 94.5330 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 85.7527 - yolo_output_0_loss: 12.5459 - yolo_output_1_loss: 69.4982\n",
      "Epoch 4: saving model to ./checkpointsTiny\\train_4.tf\n",
      "166/166 [==============================] - 7s 41ms/step - loss: 85.7680 - yolo_output_0_loss: 12.5490 - yolo_output_1_loss: 69.5104 - val_loss: 78.0888 - val_yolo_output_0_loss: 12.5244 - val_yolo_output_1_loss: 61.8561 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 61.6558 - yolo_output_0_loss: 9.9680 - yolo_output_1_loss: 47.9797\n",
      "Epoch 5: saving model to ./checkpointsTiny\\train_5.tf\n",
      "166/166 [==============================] - 7s 42ms/step - loss: 61.5776 - yolo_output_0_loss: 9.9628 - yolo_output_1_loss: 47.9067 - val_loss: 60.2586 - val_yolo_output_0_loss: 9.8485 - val_yolo_output_1_loss: 46.7023 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 46.3692 - yolo_output_0_loss: 8.3951 - yolo_output_1_loss: 34.2664\n",
      "Epoch 6: saving model to ./checkpointsTiny\\train_6.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 46.3114 - yolo_output_0_loss: 8.3867 - yolo_output_1_loss: 34.2171 - val_loss: 45.0823 - val_yolo_output_0_loss: 9.3709 - val_yolo_output_1_loss: 32.0039 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 36.7989 - yolo_output_0_loss: 7.2644 - yolo_output_1_loss: 25.8271\n",
      "Epoch 7: saving model to ./checkpointsTiny\\train_7.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 36.7909 - yolo_output_0_loss: 7.2627 - yolo_output_1_loss: 25.8208 - val_loss: 37.4855 - val_yolo_output_0_loss: 9.0839 - val_yolo_output_1_loss: 24.6943 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 30.2654 - yolo_output_0_loss: 6.5534 - yolo_output_1_loss: 20.0049\n",
      "Epoch 8: saving model to ./checkpointsTiny\\train_8.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 30.2654 - yolo_output_0_loss: 6.5534 - yolo_output_1_loss: 20.0049 - val_loss: 30.4155 - val_yolo_output_0_loss: 7.4926 - val_yolo_output_1_loss: 19.2159 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 25.8772 - yolo_output_0_loss: 6.2141 - yolo_output_1_loss: 15.9560\n",
      "Epoch 9: saving model to ./checkpointsTiny\\train_9.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 25.8772 - yolo_output_0_loss: 6.2141 - yolo_output_1_loss: 15.9560 - val_loss: 27.2786 - val_yolo_output_0_loss: 7.8618 - val_yolo_output_1_loss: 15.7097 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 22.4677 - yolo_output_0_loss: 5.7675 - yolo_output_1_loss: 12.9931\n",
      "Epoch 10: saving model to ./checkpointsTiny\\train_10.tf\n",
      "166/166 [==============================] - 7s 42ms/step - loss: 22.4900 - yolo_output_0_loss: 5.7748 - yolo_output_1_loss: 13.0081 - val_loss: 22.6850 - val_yolo_output_0_loss: 6.8665 - val_yolo_output_1_loss: 12.1115 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 19.4717 - yolo_output_0_loss: 5.1547 - yolo_output_1_loss: 10.6100\n",
      "Epoch 11: saving model to ./checkpointsTiny\\train_11.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 19.4709 - yolo_output_0_loss: 5.1518 - yolo_output_1_loss: 10.6122 - val_loss: 19.9801 - val_yolo_output_0_loss: 6.2815 - val_yolo_output_1_loss: 9.9917 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 17.3425 - yolo_output_0_loss: 4.7716 - yolo_output_1_loss: 8.8641\n",
      "Epoch 12: saving model to ./checkpointsTiny\\train_12.tf\n",
      "166/166 [==============================] - 7s 42ms/step - loss: 17.3425 - yolo_output_0_loss: 4.7716 - yolo_output_1_loss: 8.8641 - val_loss: 18.5791 - val_yolo_output_0_loss: 6.3564 - val_yolo_output_1_loss: 8.5160 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 15.5842 - yolo_output_0_loss: 4.3967 - yolo_output_1_loss: 7.4808\n",
      "Epoch 13: saving model to ./checkpointsTiny\\train_13.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 15.5839 - yolo_output_0_loss: 4.4009 - yolo_output_1_loss: 7.4764 - val_loss: 18.1905 - val_yolo_output_0_loss: 7.2364 - val_yolo_output_1_loss: 7.2475 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 14.4499 - yolo_output_0_loss: 4.3526 - yolo_output_1_loss: 6.3908\n",
      "Epoch 14: saving model to ./checkpointsTiny\\train_14.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 14.4512 - yolo_output_0_loss: 4.3514 - yolo_output_1_loss: 6.3933 - val_loss: 15.8950 - val_yolo_output_0_loss: 6.2691 - val_yolo_output_1_loss: 5.9193 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 13.4894 - yolo_output_0_loss: 4.2781 - yolo_output_1_loss: 5.5047\n",
      "Epoch 15: saving model to ./checkpointsTiny\\train_15.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 13.4816 - yolo_output_0_loss: 4.2718 - yolo_output_1_loss: 5.5032 - val_loss: 15.2498 - val_yolo_output_0_loss: 6.0971 - val_yolo_output_1_loss: 5.4460 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 12.3537 - yolo_output_0_loss: 3.8646 - yolo_output_1_loss: 4.7825\n",
      "Epoch 16: saving model to ./checkpointsTiny\\train_16.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 12.3537 - yolo_output_0_loss: 3.8646 - yolo_output_1_loss: 4.7825 - val_loss: 14.1163 - val_yolo_output_0_loss: 5.9220 - val_yolo_output_1_loss: 4.4877 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 11.3681 - yolo_output_0_loss: 3.4727 - yolo_output_1_loss: 4.1889\n",
      "Epoch 17: saving model to ./checkpointsTiny\\train_17.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 11.3681 - yolo_output_0_loss: 3.4727 - yolo_output_1_loss: 4.1889 - val_loss: 14.8207 - val_yolo_output_0_loss: 7.3483 - val_yolo_output_1_loss: 3.7661 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "164/166 [============================>.] - ETA: 0s - loss: 10.6127 - yolo_output_0_loss: 3.2234 - yolo_output_1_loss: 3.6831\n",
      "Epoch 18: saving model to ./checkpointsTiny\\train_18.tf\n",
      "166/166 [==============================] - 7s 43ms/step - loss: 10.6108 - yolo_output_0_loss: 3.2247 - yolo_output_1_loss: 3.6799 - val_loss: 13.2313 - val_yolo_output_0_loss: 6.2064 - val_yolo_output_1_loss: 3.3187 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 10.0568 - yolo_output_0_loss: 3.1229 - yolo_output_1_loss: 3.2279\n",
      "Epoch 19: saving model to ./checkpointsTiny\\train_19.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 10.0756 - yolo_output_0_loss: 3.1253 - yolo_output_1_loss: 3.2442 - val_loss: 13.7845 - val_yolo_output_0_loss: 7.1058 - val_yolo_output_1_loss: 2.9727 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 9.5083 - yolo_output_0_loss: 2.8938 - yolo_output_1_loss: 2.9085\n",
      "Epoch 20: saving model to ./checkpointsTiny\\train_20.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 9.5071 - yolo_output_0_loss: 2.8913 - yolo_output_1_loss: 2.9099 - val_loss: 14.2246 - val_yolo_output_0_loss: 7.9547 - val_yolo_output_1_loss: 2.5641 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 8.9634 - yolo_output_0_loss: 2.6639 - yolo_output_1_loss: 2.5938\n",
      "Epoch 21: saving model to ./checkpointsTiny\\train_21.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 8.9634 - yolo_output_0_loss: 2.6639 - yolo_output_1_loss: 2.5938 - val_loss: 12.8286 - val_yolo_output_0_loss: 6.8755 - val_yolo_output_1_loss: 2.2474 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 8.6010 - yolo_output_0_loss: 2.5747 - yolo_output_1_loss: 2.3205\n",
      "Epoch 22: saving model to ./checkpointsTiny\\train_22.tf\n",
      "166/166 [==============================] - 7s 44ms/step - loss: 8.6009 - yolo_output_0_loss: 2.5750 - yolo_output_1_loss: 2.3202 - val_loss: 12.3376 - val_yolo_output_0_loss: 6.6764 - val_yolo_output_1_loss: 1.9555 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 8.1656 - yolo_output_0_loss: 2.3815 - yolo_output_1_loss: 2.0785\n",
      "Epoch 23: saving model to ./checkpointsTiny\\train_23.tf\n",
      "166/166 [==============================] - 8s 45ms/step - loss: 8.1655 - yolo_output_0_loss: 2.3815 - yolo_output_1_loss: 2.0785 - val_loss: 12.1122 - val_yolo_output_0_loss: 6.5331 - val_yolo_output_1_loss: 1.8736 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 8.0302 - yolo_output_0_loss: 2.4533 - yolo_output_1_loss: 1.8713\n",
      "Epoch 24: saving model to ./checkpointsTiny\\train_24.tf\n",
      "166/166 [==============================] - 8s 45ms/step - loss: 8.0302 - yolo_output_0_loss: 2.4533 - yolo_output_1_loss: 1.8713 - val_loss: 12.4158 - val_yolo_output_0_loss: 7.1301 - val_yolo_output_1_loss: 1.5800 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 7.4219 - yolo_output_0_loss: 2.0124 - yolo_output_1_loss: 1.7038\n",
      "Epoch 25: saving model to ./checkpointsTiny\\train_25.tf\n",
      "166/166 [==============================] - 8s 45ms/step - loss: 7.4195 - yolo_output_0_loss: 2.0109 - yolo_output_1_loss: 1.7030 - val_loss: 12.6525 - val_yolo_output_0_loss: 7.5232 - val_yolo_output_1_loss: 1.4238 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 7.0230 - yolo_output_0_loss: 1.7761 - yolo_output_1_loss: 1.5417\n",
      "Epoch 26: saving model to ./checkpointsTiny\\train_26.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 7.0213 - yolo_output_0_loss: 1.7749 - yolo_output_1_loss: 1.5411 - val_loss: 13.0845 - val_yolo_output_0_loss: 8.0963 - val_yolo_output_1_loss: 1.2831 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.7439 - yolo_output_0_loss: 1.6486 - yolo_output_1_loss: 1.3904\n",
      "Epoch 27: saving model to ./checkpointsTiny\\train_27.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 6.7439 - yolo_output_0_loss: 1.6486 - yolo_output_1_loss: 1.3904 - val_loss: 12.9787 - val_yolo_output_0_loss: 8.0960 - val_yolo_output_1_loss: 1.1780 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.4585 - yolo_output_0_loss: 1.4799 - yolo_output_1_loss: 1.2741\n",
      "Epoch 28: saving model to ./checkpointsTiny\\train_28.tf\n",
      "166/166 [==============================] - 8s 47ms/step - loss: 6.4585 - yolo_output_0_loss: 1.4799 - yolo_output_1_loss: 1.2741 - val_loss: 12.6194 - val_yolo_output_0_loss: 7.8456 - val_yolo_output_1_loss: 1.0695 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 6.2454 - yolo_output_0_loss: 1.3929 - yolo_output_1_loss: 1.1485\n",
      "Epoch 29: saving model to ./checkpointsTiny\\train_29.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 6.2453 - yolo_output_0_loss: 1.3931 - yolo_output_1_loss: 1.1482 - val_loss: 13.3891 - val_yolo_output_0_loss: 8.7695 - val_yolo_output_1_loss: 0.9158 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 6.0154 - yolo_output_0_loss: 1.2639 - yolo_output_1_loss: 1.0479\n",
      "Epoch 30: saving model to ./checkpointsTiny\\train_30.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 6.0154 - yolo_output_0_loss: 1.2639 - yolo_output_1_loss: 1.0479 - val_loss: 13.0521 - val_yolo_output_0_loss: 8.4916 - val_yolo_output_1_loss: 0.8572 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 5.8747 - yolo_output_0_loss: 1.1977 - yolo_output_1_loss: 0.9738\n",
      "Epoch 31: saving model to ./checkpointsTiny\\train_31.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 5.8747 - yolo_output_0_loss: 1.1977 - yolo_output_1_loss: 0.9738 - val_loss: 12.6077 - val_yolo_output_0_loss: 8.1715 - val_yolo_output_1_loss: 0.7333 - lr: 1.0000e-04\n",
      "Epoch 32/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 5.7355 - yolo_output_0_loss: 1.1111 - yolo_output_1_loss: 0.9217\n",
      "Epoch 32: saving model to ./checkpointsTiny\\train_32.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 5.7406 - yolo_output_0_loss: 1.1124 - yolo_output_1_loss: 0.9255 - val_loss: 11.8596 - val_yolo_output_0_loss: 7.4530 - val_yolo_output_1_loss: 0.7042 - lr: 1.0000e-04\n",
      "Epoch 33/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 5.5809 - yolo_output_0_loss: 1.0322 - yolo_output_1_loss: 0.8464\n",
      "Epoch 33: saving model to ./checkpointsTiny\\train_33.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 5.5804 - yolo_output_0_loss: 1.0320 - yolo_output_1_loss: 0.8463 - val_loss: 14.3617 - val_yolo_output_0_loss: 10.0188 - val_yolo_output_1_loss: 0.6410 - lr: 1.0000e-04\n",
      "Epoch 34/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 5.4283 - yolo_output_0_loss: 0.9860 - yolo_output_1_loss: 0.7407\n",
      "Epoch 34: saving model to ./checkpointsTiny\\train_34.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 5.4274 - yolo_output_0_loss: 0.9856 - yolo_output_1_loss: 0.7401 - val_loss: 12.5289 - val_yolo_output_0_loss: 8.2677 - val_yolo_output_1_loss: 0.5600 - lr: 1.0000e-04\n",
      "Epoch 35/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 5.2357 - yolo_output_0_loss: 0.8446 - yolo_output_1_loss: 0.6902\n",
      "Epoch 35: saving model to ./checkpointsTiny\\train_35.tf\n",
      "166/166 [==============================] - 9s 51ms/step - loss: 5.2357 - yolo_output_0_loss: 0.8446 - yolo_output_1_loss: 0.6902 - val_loss: 14.1227 - val_yolo_output_0_loss: 9.9147 - val_yolo_output_1_loss: 0.5077 - lr: 1.0000e-04\n",
      "Epoch 36/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 5.0323 - yolo_output_0_loss: 0.7171 - yolo_output_1_loss: 0.6154\n",
      "Epoch 36: saving model to ./checkpointsTiny\\train_36.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 5.0317 - yolo_output_0_loss: 0.7169 - yolo_output_1_loss: 0.6150 - val_loss: 13.9193 - val_yolo_output_0_loss: 9.7097 - val_yolo_output_1_loss: 0.5103 - lr: 1.0000e-04\n",
      "Epoch 37/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.9018 - yolo_output_0_loss: 0.6398 - yolo_output_1_loss: 0.5633\n",
      "Epoch 37: saving model to ./checkpointsTiny\\train_37.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.9018 - yolo_output_0_loss: 0.6401 - yolo_output_1_loss: 0.5630 - val_loss: 14.3631 - val_yolo_output_0_loss: 10.2362 - val_yolo_output_1_loss: 0.4288 - lr: 1.0000e-04\n",
      "Epoch 38/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.7998 - yolo_output_0_loss: 0.5880 - yolo_output_1_loss: 0.5143\n",
      "Epoch 38: saving model to ./checkpointsTiny\\train_38.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.7998 - yolo_output_0_loss: 0.5880 - yolo_output_1_loss: 0.5143 - val_loss: 13.6887 - val_yolo_output_0_loss: 9.6215 - val_yolo_output_1_loss: 0.3703 - lr: 1.0000e-04\n",
      "Epoch 39/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.7908 - yolo_output_0_loss: 0.6018 - yolo_output_1_loss: 0.4926\n",
      "Epoch 39: saving model to ./checkpointsTiny\\train_39.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.7908 - yolo_output_0_loss: 0.6018 - yolo_output_1_loss: 0.4926 - val_loss: 12.5029 - val_yolo_output_0_loss: 8.4548 - val_yolo_output_1_loss: 0.3524 - lr: 1.0000e-04\n",
      "Epoch 40/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.7816 - yolo_output_0_loss: 0.6282 - yolo_output_1_loss: 0.4582\n",
      "Epoch 40: saving model to ./checkpointsTiny\\train_40.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.7805 - yolo_output_0_loss: 0.6274 - yolo_output_1_loss: 0.4579 - val_loss: 13.5006 - val_yolo_output_0_loss: 9.5139 - val_yolo_output_1_loss: 0.2921 - lr: 1.0000e-04\n",
      "Epoch 41/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.6740 - yolo_output_0_loss: 0.5567 - yolo_output_1_loss: 0.4233\n",
      "Epoch 41: saving model to ./checkpointsTiny\\train_41.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.6740 - yolo_output_0_loss: 0.5567 - yolo_output_1_loss: 0.4233 - val_loss: 15.1795 - val_yolo_output_0_loss: 11.1801 - val_yolo_output_1_loss: 0.3061 - lr: 1.0000e-04\n",
      "Epoch 42/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.6064 - yolo_output_0_loss: 0.5105 - yolo_output_1_loss: 0.4031\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-06.\n",
      "\n",
      "Epoch 42: saving model to ./checkpointsTiny\\train_42.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.6062 - yolo_output_0_loss: 0.5100 - yolo_output_1_loss: 0.4035 - val_loss: 14.3909 - val_yolo_output_0_loss: 10.4418 - val_yolo_output_1_loss: 0.2570 - lr: 1.0000e-04\n",
      "Epoch 43/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.4399 - yolo_output_0_loss: 0.3996 - yolo_output_1_loss: 0.3483\n",
      "Epoch 43: saving model to ./checkpointsTiny\\train_43.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.4399 - yolo_output_0_loss: 0.3996 - yolo_output_1_loss: 0.3483 - val_loss: 13.3310 - val_yolo_output_0_loss: 9.3756 - val_yolo_output_1_loss: 0.2635 - lr: 1.0000e-05\n",
      "Epoch 44/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.3486 - yolo_output_0_loss: 0.3207 - yolo_output_1_loss: 0.3361\n",
      "Epoch 44: saving model to ./checkpointsTiny\\train_44.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.3486 - yolo_output_0_loss: 0.3207 - yolo_output_1_loss: 0.3361 - val_loss: 13.6950 - val_yolo_output_0_loss: 9.7476 - val_yolo_output_1_loss: 0.2557 - lr: 1.0000e-05\n",
      "Epoch 45/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.2930 - yolo_output_0_loss: 0.2851 - yolo_output_1_loss: 0.3165\n",
      "Epoch 45: saving model to ./checkpointsTiny\\train_45.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.2945 - yolo_output_0_loss: 0.2865 - yolo_output_1_loss: 0.3166 - val_loss: 13.8205 - val_yolo_output_0_loss: 9.8735 - val_yolo_output_1_loss: 0.2556 - lr: 1.0000e-05\n",
      "Epoch 46/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.2568 - yolo_output_0_loss: 0.2589 - yolo_output_1_loss: 0.3067\n",
      "Epoch 46: saving model to ./checkpointsTiny\\train_46.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.2568 - yolo_output_0_loss: 0.2589 - yolo_output_1_loss: 0.3067 - val_loss: 13.7361 - val_yolo_output_0_loss: 9.7950 - val_yolo_output_1_loss: 0.2501 - lr: 1.0000e-05\n",
      "Epoch 47/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.2326 - yolo_output_0_loss: 0.2409 - yolo_output_1_loss: 0.3008\n",
      "Epoch 47: saving model to ./checkpointsTiny\\train_47.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.2325 - yolo_output_0_loss: 0.2409 - yolo_output_1_loss: 0.3007 - val_loss: 13.8372 - val_yolo_output_0_loss: 9.9000 - val_yolo_output_1_loss: 0.2465 - lr: 1.0000e-05\n",
      "Epoch 48/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.2115 - yolo_output_0_loss: 0.2287 - yolo_output_1_loss: 0.2922\n",
      "Epoch 48: saving model to ./checkpointsTiny\\train_48.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.2115 - yolo_output_0_loss: 0.2289 - yolo_output_1_loss: 0.2921 - val_loss: 13.9502 - val_yolo_output_0_loss: 10.0180 - val_yolo_output_1_loss: 0.2419 - lr: 1.0000e-05\n",
      "Epoch 49/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.2004 - yolo_output_0_loss: 0.2210 - yolo_output_1_loss: 0.2892\n",
      "Epoch 49: saving model to ./checkpointsTiny\\train_49.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.2004 - yolo_output_0_loss: 0.2210 - yolo_output_1_loss: 0.2892 - val_loss: 14.0212 - val_yolo_output_0_loss: 10.0924 - val_yolo_output_1_loss: 0.2389 - lr: 1.0000e-05\n",
      "Epoch 50/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1792 - yolo_output_0_loss: 0.2089 - yolo_output_1_loss: 0.2805\n",
      "Epoch 50: saving model to ./checkpointsTiny\\train_50.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1792 - yolo_output_0_loss: 0.2089 - yolo_output_1_loss: 0.2805 - val_loss: 13.8987 - val_yolo_output_0_loss: 9.9754 - val_yolo_output_1_loss: 0.2337 - lr: 1.0000e-05\n",
      "Epoch 51/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1724 - yolo_output_0_loss: 0.2053 - yolo_output_1_loss: 0.2777\n",
      "Epoch 51: saving model to ./checkpointsTiny\\train_51.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1724 - yolo_output_0_loss: 0.2053 - yolo_output_1_loss: 0.2777 - val_loss: 13.9582 - val_yolo_output_0_loss: 10.0388 - val_yolo_output_1_loss: 0.2301 - lr: 1.0000e-05\n",
      "Epoch 52/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1608 - yolo_output_0_loss: 0.2015 - yolo_output_1_loss: 0.2703\n",
      "Epoch 52: ReduceLROnPlateau reducing learning rate to 9.999999747378752e-07.\n",
      "\n",
      "Epoch 52: saving model to ./checkpointsTiny\\train_52.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1608 - yolo_output_0_loss: 0.2015 - yolo_output_1_loss: 0.2703 - val_loss: 14.0202 - val_yolo_output_0_loss: 10.1052 - val_yolo_output_1_loss: 0.2262 - lr: 1.0000e-05\n",
      "Epoch 53/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1474 - yolo_output_0_loss: 0.1909 - yolo_output_1_loss: 0.2677\n",
      "Epoch 53: saving model to ./checkpointsTiny\\train_53.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1474 - yolo_output_0_loss: 0.1909 - yolo_output_1_loss: 0.2677 - val_loss: 14.0326 - val_yolo_output_0_loss: 10.1211 - val_yolo_output_1_loss: 0.2227 - lr: 1.0000e-06\n",
      "Epoch 54/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1451 - yolo_output_0_loss: 0.1907 - yolo_output_1_loss: 0.2657\n",
      "Epoch 54: saving model to ./checkpointsTiny\\train_54.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1452 - yolo_output_0_loss: 0.1908 - yolo_output_1_loss: 0.2657 - val_loss: 14.0622 - val_yolo_output_0_loss: 10.1502 - val_yolo_output_1_loss: 0.2233 - lr: 1.0000e-06\n",
      "Epoch 55/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1450 - yolo_output_0_loss: 0.1899 - yolo_output_1_loss: 0.2665\n",
      "Epoch 55: saving model to ./checkpointsTiny\\train_55.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1456 - yolo_output_0_loss: 0.1904 - yolo_output_1_loss: 0.2666 - val_loss: 14.0823 - val_yolo_output_0_loss: 10.1710 - val_yolo_output_1_loss: 0.2227 - lr: 1.0000e-06\n",
      "Epoch 56/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1440 - yolo_output_0_loss: 0.1900 - yolo_output_1_loss: 0.2654\n",
      "Epoch 56: saving model to ./checkpointsTiny\\train_56.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1439 - yolo_output_0_loss: 0.1900 - yolo_output_1_loss: 0.2653 - val_loss: 14.0531 - val_yolo_output_0_loss: 10.1421 - val_yolo_output_1_loss: 0.2225 - lr: 1.0000e-06\n",
      "Epoch 57/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1371 - yolo_output_0_loss: 0.1858 - yolo_output_1_loss: 0.2628\n",
      "Epoch 57: saving model to ./checkpointsTiny\\train_57.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1381 - yolo_output_0_loss: 0.1860 - yolo_output_1_loss: 0.2636 - val_loss: 14.0691 - val_yolo_output_0_loss: 10.1597 - val_yolo_output_1_loss: 0.2208 - lr: 1.0000e-06\n",
      "Epoch 58/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1381 - yolo_output_0_loss: 0.1855 - yolo_output_1_loss: 0.2641\n",
      "Epoch 58: saving model to ./checkpointsTiny\\train_58.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1380 - yolo_output_0_loss: 0.1855 - yolo_output_1_loss: 0.2641 - val_loss: 14.1170 - val_yolo_output_0_loss: 10.2062 - val_yolo_output_1_loss: 0.2224 - lr: 1.0000e-06\n",
      "Epoch 59/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1370 - yolo_output_0_loss: 0.1845 - yolo_output_1_loss: 0.2642\n",
      "Epoch 59: saving model to ./checkpointsTiny\\train_59.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1370 - yolo_output_0_loss: 0.1845 - yolo_output_1_loss: 0.2642 - val_loss: 14.0833 - val_yolo_output_0_loss: 10.1732 - val_yolo_output_1_loss: 0.2218 - lr: 1.0000e-06\n",
      "Epoch 60/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1365 - yolo_output_0_loss: 0.1855 - yolo_output_1_loss: 0.2626\n",
      "Epoch 60: saving model to ./checkpointsTiny\\train_60.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1365 - yolo_output_0_loss: 0.1855 - yolo_output_1_loss: 0.2626 - val_loss: 14.1087 - val_yolo_output_0_loss: 10.2005 - val_yolo_output_1_loss: 0.2199 - lr: 1.0000e-06\n",
      "Epoch 61/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1336 - yolo_output_0_loss: 0.1844 - yolo_output_1_loss: 0.2609\n",
      "Epoch 61: saving model to ./checkpointsTiny\\train_61.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1336 - yolo_output_0_loss: 0.1844 - yolo_output_1_loss: 0.2609 - val_loss: 14.1633 - val_yolo_output_0_loss: 10.2550 - val_yolo_output_1_loss: 0.2200 - lr: 1.0000e-06\n",
      "Epoch 62/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1292 - yolo_output_0_loss: 0.1825 - yolo_output_1_loss: 0.2586\n",
      "Epoch 62: ReduceLROnPlateau reducing learning rate to 9.999999974752428e-08.\n",
      "\n",
      "Epoch 62: saving model to ./checkpointsTiny\\train_62.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1292 - yolo_output_0_loss: 0.1825 - yolo_output_1_loss: 0.2586 - val_loss: 14.1581 - val_yolo_output_0_loss: 10.2521 - val_yolo_output_1_loss: 0.2178 - lr: 1.0000e-06\n",
      "Epoch 63/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1292 - yolo_output_0_loss: 0.1820 - yolo_output_1_loss: 0.2591\n",
      "Epoch 63: saving model to ./checkpointsTiny\\train_63.tf\n",
      "166/166 [==============================] - 9s 51ms/step - loss: 4.1292 - yolo_output_0_loss: 0.1820 - yolo_output_1_loss: 0.2591 - val_loss: 14.1775 - val_yolo_output_0_loss: 10.2719 - val_yolo_output_1_loss: 0.2175 - lr: 1.0000e-07\n",
      "Epoch 64/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1261 - yolo_output_0_loss: 0.1806 - yolo_output_1_loss: 0.2573\n",
      "Epoch 64: saving model to ./checkpointsTiny\\train_64.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1261 - yolo_output_0_loss: 0.1806 - yolo_output_1_loss: 0.2573 - val_loss: 14.1523 - val_yolo_output_0_loss: 10.2470 - val_yolo_output_1_loss: 0.2171 - lr: 1.0000e-07\n",
      "Epoch 65/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1272 - yolo_output_0_loss: 0.1810 - yolo_output_1_loss: 0.2581\n",
      "Epoch 65: saving model to ./checkpointsTiny\\train_65.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1272 - yolo_output_0_loss: 0.1810 - yolo_output_1_loss: 0.2581 - val_loss: 14.1659 - val_yolo_output_0_loss: 10.2613 - val_yolo_output_1_loss: 0.2165 - lr: 1.0000e-07\n",
      "Epoch 66/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1255 - yolo_output_0_loss: 0.1803 - yolo_output_1_loss: 0.2572\n",
      "Epoch 66: saving model to ./checkpointsTiny\\train_66.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1256 - yolo_output_0_loss: 0.1804 - yolo_output_1_loss: 0.2571 - val_loss: 14.1696 - val_yolo_output_0_loss: 10.2650 - val_yolo_output_1_loss: 0.2165 - lr: 1.0000e-07\n",
      "Epoch 67/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1271 - yolo_output_0_loss: 0.1821 - yolo_output_1_loss: 0.2570\n",
      "Epoch 67: saving model to ./checkpointsTiny\\train_67.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1299 - yolo_output_0_loss: 0.1823 - yolo_output_1_loss: 0.2595 - val_loss: 14.1588 - val_yolo_output_0_loss: 10.2516 - val_yolo_output_1_loss: 0.2190 - lr: 1.0000e-07\n",
      "Epoch 68/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1258 - yolo_output_0_loss: 0.1798 - yolo_output_1_loss: 0.2579\n",
      "Epoch 68: saving model to ./checkpointsTiny\\train_68.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1261 - yolo_output_0_loss: 0.1799 - yolo_output_1_loss: 0.2582 - val_loss: 14.1700 - val_yolo_output_0_loss: 10.2648 - val_yolo_output_1_loss: 0.2170 - lr: 1.0000e-07\n",
      "Epoch 69/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1229 - yolo_output_0_loss: 0.1786 - yolo_output_1_loss: 0.2562\n",
      "Epoch 69: saving model to ./checkpointsTiny\\train_69.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1229 - yolo_output_0_loss: 0.1786 - yolo_output_1_loss: 0.2562 - val_loss: 14.1534 - val_yolo_output_0_loss: 10.2480 - val_yolo_output_1_loss: 0.2173 - lr: 1.0000e-07\n",
      "Epoch 70/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1248 - yolo_output_0_loss: 0.1797 - yolo_output_1_loss: 0.2570\n",
      "Epoch 70: saving model to ./checkpointsTiny\\train_70.tf\n",
      "166/166 [==============================] - 9s 51ms/step - loss: 4.1251 - yolo_output_0_loss: 0.1797 - yolo_output_1_loss: 0.2574 - val_loss: 14.1502 - val_yolo_output_0_loss: 10.2454 - val_yolo_output_1_loss: 0.2167 - lr: 1.0000e-07\n",
      "Epoch 71/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1262 - yolo_output_0_loss: 0.1811 - yolo_output_1_loss: 0.2570\n",
      "Epoch 71: saving model to ./checkpointsTiny\\train_71.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1259 - yolo_output_0_loss: 0.1809 - yolo_output_1_loss: 0.2570 - val_loss: 14.1633 - val_yolo_output_0_loss: 10.2590 - val_yolo_output_1_loss: 0.2163 - lr: 1.0000e-07\n",
      "Epoch 72/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1261 - yolo_output_0_loss: 0.1804 - yolo_output_1_loss: 0.2577\n",
      "Epoch 72: ReduceLROnPlateau reducing learning rate to 1.0000000116860975e-08.\n",
      "\n",
      "Epoch 72: saving model to ./checkpointsTiny\\train_72.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1261 - yolo_output_0_loss: 0.1804 - yolo_output_1_loss: 0.2577 - val_loss: 14.1679 - val_yolo_output_0_loss: 10.2626 - val_yolo_output_1_loss: 0.2173 - lr: 1.0000e-07\n",
      "Epoch 73/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1255 - yolo_output_0_loss: 0.1807 - yolo_output_1_loss: 0.2568\n",
      "Epoch 73: saving model to ./checkpointsTiny\\train_73.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1255 - yolo_output_0_loss: 0.1807 - yolo_output_1_loss: 0.2568 - val_loss: 14.1698 - val_yolo_output_0_loss: 10.2666 - val_yolo_output_1_loss: 0.2152 - lr: 1.0000e-08\n",
      "Epoch 74/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1280 - yolo_output_0_loss: 0.1830 - yolo_output_1_loss: 0.2570\n",
      "Epoch 74: saving model to ./checkpointsTiny\\train_74.tf\n",
      "166/166 [==============================] - 8s 47ms/step - loss: 4.1280 - yolo_output_0_loss: 0.1830 - yolo_output_1_loss: 0.2570 - val_loss: 14.1694 - val_yolo_output_0_loss: 10.2648 - val_yolo_output_1_loss: 0.2165 - lr: 1.0000e-08\n",
      "Epoch 75/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1245 - yolo_output_0_loss: 0.1785 - yolo_output_1_loss: 0.2580\n",
      "Epoch 75: saving model to ./checkpointsTiny\\train_75.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1245 - yolo_output_0_loss: 0.1784 - yolo_output_1_loss: 0.2581 - val_loss: 14.1712 - val_yolo_output_0_loss: 10.2653 - val_yolo_output_1_loss: 0.2179 - lr: 1.0000e-08\n",
      "Epoch 76/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1240 - yolo_output_0_loss: 0.1795 - yolo_output_1_loss: 0.2564\n",
      "Epoch 76: saving model to ./checkpointsTiny\\train_76.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1240 - yolo_output_0_loss: 0.1795 - yolo_output_1_loss: 0.2564 - val_loss: 14.1609 - val_yolo_output_0_loss: 10.2575 - val_yolo_output_1_loss: 0.2154 - lr: 1.0000e-08\n",
      "Epoch 77/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1286 - yolo_output_0_loss: 0.1818 - yolo_output_1_loss: 0.2588\n",
      "Epoch 77: saving model to ./checkpointsTiny\\train_77.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1293 - yolo_output_0_loss: 0.1825 - yolo_output_1_loss: 0.2588 - val_loss: 14.1709 - val_yolo_output_0_loss: 10.2664 - val_yolo_output_1_loss: 0.2164 - lr: 1.0000e-08\n",
      "Epoch 78/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1246 - yolo_output_0_loss: 0.1802 - yolo_output_1_loss: 0.2563\n",
      "Epoch 78: saving model to ./checkpointsTiny\\train_78.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1246 - yolo_output_0_loss: 0.1802 - yolo_output_1_loss: 0.2563 - val_loss: 14.1896 - val_yolo_output_0_loss: 10.2856 - val_yolo_output_1_loss: 0.2159 - lr: 1.0000e-08\n",
      "Epoch 79/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1260 - yolo_output_0_loss: 0.1815 - yolo_output_1_loss: 0.2565\n",
      "Epoch 79: saving model to ./checkpointsTiny\\train_79.tf\n",
      "166/166 [==============================] - 8s 48ms/step - loss: 4.1260 - yolo_output_0_loss: 0.1815 - yolo_output_1_loss: 0.2565 - val_loss: 14.1656 - val_yolo_output_0_loss: 10.2622 - val_yolo_output_1_loss: 0.2153 - lr: 1.0000e-08\n",
      "Epoch 80/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1222 - yolo_output_0_loss: 0.1791 - yolo_output_1_loss: 0.2552\n",
      "Epoch 80: saving model to ./checkpointsTiny\\train_80.tf\n",
      "166/166 [==============================] - 9s 51ms/step - loss: 4.1232 - yolo_output_0_loss: 0.1790 - yolo_output_1_loss: 0.2562 - val_loss: 14.1653 - val_yolo_output_0_loss: 10.2616 - val_yolo_output_1_loss: 0.2156 - lr: 1.0000e-08\n",
      "Epoch 81/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1255 - yolo_output_0_loss: 0.1800 - yolo_output_1_loss: 0.2575\n",
      "Epoch 81: saving model to ./checkpointsTiny\\train_81.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1255 - yolo_output_0_loss: 0.1800 - yolo_output_1_loss: 0.2575 - val_loss: 14.1735 - val_yolo_output_0_loss: 10.2695 - val_yolo_output_1_loss: 0.2159 - lr: 1.0000e-08\n",
      "Epoch 82/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1220 - yolo_output_0_loss: 0.1786 - yolo_output_1_loss: 0.2554\n",
      "Epoch 82: ReduceLROnPlateau reducing learning rate to 9.999999939225292e-10.\n",
      "\n",
      "Epoch 82: saving model to ./checkpointsTiny\\train_82.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1220 - yolo_output_0_loss: 0.1787 - yolo_output_1_loss: 0.2553 - val_loss: 14.1617 - val_yolo_output_0_loss: 10.2583 - val_yolo_output_1_loss: 0.2154 - lr: 1.0000e-08\n",
      "Epoch 83/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1272 - yolo_output_0_loss: 0.1822 - yolo_output_1_loss: 0.2569\n",
      "Epoch 83: saving model to ./checkpointsTiny\\train_83.tf\n",
      "166/166 [==============================] - 8s 49ms/step - loss: 4.1279 - yolo_output_0_loss: 0.1827 - yolo_output_1_loss: 0.2572 - val_loss: 14.1651 - val_yolo_output_0_loss: 10.2604 - val_yolo_output_1_loss: 0.2166 - lr: 1.0000e-09\n",
      "Epoch 84/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1285 - yolo_output_0_loss: 0.1815 - yolo_output_1_loss: 0.2590\n",
      "Epoch 84: saving model to ./checkpointsTiny\\train_84.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1285 - yolo_output_0_loss: 0.1815 - yolo_output_1_loss: 0.2590 - val_loss: 14.1619 - val_yolo_output_0_loss: 10.2589 - val_yolo_output_1_loss: 0.2150 - lr: 1.0000e-09\n",
      "Epoch 85/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1328 - yolo_output_0_loss: 0.1855 - yolo_output_1_loss: 0.2592\n",
      "Epoch 85: saving model to ./checkpointsTiny\\train_85.tf\n",
      "166/166 [==============================] - 9s 50ms/step - loss: 4.1328 - yolo_output_0_loss: 0.1855 - yolo_output_1_loss: 0.2592 - val_loss: 14.1626 - val_yolo_output_0_loss: 10.2586 - val_yolo_output_1_loss: 0.2161 - lr: 1.0000e-09\n",
      "Epoch 86/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1300 - yolo_output_0_loss: 0.1835 - yolo_output_1_loss: 0.2585\n",
      "Epoch 86: saving model to ./checkpointsTiny\\train_86.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1300 - yolo_output_0_loss: 0.1835 - yolo_output_1_loss: 0.2585 - val_loss: 14.1480 - val_yolo_output_0_loss: 10.2420 - val_yolo_output_1_loss: 0.2180 - lr: 1.0000e-09\n",
      "Epoch 87/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1242 - yolo_output_0_loss: 0.1790 - yolo_output_1_loss: 0.2571\n",
      "Epoch 87: saving model to ./checkpointsTiny\\train_87.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1242 - yolo_output_0_loss: 0.1790 - yolo_output_1_loss: 0.2571 - val_loss: 14.1776 - val_yolo_output_0_loss: 10.2736 - val_yolo_output_1_loss: 0.2160 - lr: 1.0000e-09\n",
      "Epoch 88/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1275 - yolo_output_0_loss: 0.1820 - yolo_output_1_loss: 0.2574\n",
      "Epoch 88: saving model to ./checkpointsTiny\\train_88.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1275 - yolo_output_0_loss: 0.1820 - yolo_output_1_loss: 0.2574 - val_loss: 14.1624 - val_yolo_output_0_loss: 10.2574 - val_yolo_output_1_loss: 0.2169 - lr: 1.0000e-09\n",
      "Epoch 89/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1215 - yolo_output_0_loss: 0.1786 - yolo_output_1_loss: 0.2549\n",
      "Epoch 89: saving model to ./checkpointsTiny\\train_89.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1213 - yolo_output_0_loss: 0.1784 - yolo_output_1_loss: 0.2549 - val_loss: 14.1823 - val_yolo_output_0_loss: 10.2778 - val_yolo_output_1_loss: 0.2165 - lr: 1.0000e-09\n",
      "Epoch 90/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1290 - yolo_output_0_loss: 0.1817 - yolo_output_1_loss: 0.2592\n",
      "Epoch 90: saving model to ./checkpointsTiny\\train_90.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1290 - yolo_output_0_loss: 0.1817 - yolo_output_1_loss: 0.2592 - val_loss: 14.1680 - val_yolo_output_0_loss: 10.2636 - val_yolo_output_1_loss: 0.2164 - lr: 1.0000e-09\n",
      "Epoch 91/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1249 - yolo_output_0_loss: 0.1803 - yolo_output_1_loss: 0.2566\n",
      "Epoch 91: saving model to ./checkpointsTiny\\train_91.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1249 - yolo_output_0_loss: 0.1803 - yolo_output_1_loss: 0.2566 - val_loss: 14.1567 - val_yolo_output_0_loss: 10.2538 - val_yolo_output_1_loss: 0.2149 - lr: 1.0000e-09\n",
      "Epoch 92/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1242 - yolo_output_0_loss: 0.1800 - yolo_output_1_loss: 0.2562\n",
      "Epoch 92: ReduceLROnPlateau reducing learning rate to 9.999999717180686e-11.\n",
      "\n",
      "Epoch 92: saving model to ./checkpointsTiny\\train_92.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1245 - yolo_output_0_loss: 0.1802 - yolo_output_1_loss: 0.2562 - val_loss: 14.1698 - val_yolo_output_0_loss: 10.2660 - val_yolo_output_1_loss: 0.2157 - lr: 1.0000e-09\n",
      "Epoch 93/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1290 - yolo_output_0_loss: 0.1839 - yolo_output_1_loss: 0.2571\n",
      "Epoch 93: saving model to ./checkpointsTiny\\train_93.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1290 - yolo_output_0_loss: 0.1839 - yolo_output_1_loss: 0.2571 - val_loss: 14.1802 - val_yolo_output_0_loss: 10.2761 - val_yolo_output_1_loss: 0.2161 - lr: 1.0000e-10\n",
      "Epoch 94/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1286 - yolo_output_0_loss: 0.1791 - yolo_output_1_loss: 0.2615\n",
      "Epoch 94: saving model to ./checkpointsTiny\\train_94.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1287 - yolo_output_0_loss: 0.1792 - yolo_output_1_loss: 0.2614 - val_loss: 14.1674 - val_yolo_output_0_loss: 10.2639 - val_yolo_output_1_loss: 0.2154 - lr: 1.0000e-10\n",
      "Epoch 95/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1236 - yolo_output_0_loss: 0.1795 - yolo_output_1_loss: 0.2561\n",
      "Epoch 95: saving model to ./checkpointsTiny\\train_95.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1235 - yolo_output_0_loss: 0.1794 - yolo_output_1_loss: 0.2561 - val_loss: 14.1779 - val_yolo_output_0_loss: 10.2749 - val_yolo_output_1_loss: 0.2149 - lr: 1.0000e-10\n",
      "Epoch 96/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1238 - yolo_output_0_loss: 0.1798 - yolo_output_1_loss: 0.2559\n",
      "Epoch 96: saving model to ./checkpointsTiny\\train_96.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1237 - yolo_output_0_loss: 0.1798 - yolo_output_1_loss: 0.2559 - val_loss: 14.1785 - val_yolo_output_0_loss: 10.2755 - val_yolo_output_1_loss: 0.2150 - lr: 1.0000e-10\n",
      "Epoch 97/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1299 - yolo_output_0_loss: 0.1826 - yolo_output_1_loss: 0.2593\n",
      "Epoch 97: saving model to ./checkpointsTiny\\train_97.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1297 - yolo_output_0_loss: 0.1825 - yolo_output_1_loss: 0.2592 - val_loss: 14.1679 - val_yolo_output_0_loss: 10.2634 - val_yolo_output_1_loss: 0.2165 - lr: 1.0000e-10\n",
      "Epoch 98/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1237 - yolo_output_0_loss: 0.1793 - yolo_output_1_loss: 0.2564\n",
      "Epoch 98: saving model to ./checkpointsTiny\\train_98.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1238 - yolo_output_0_loss: 0.1795 - yolo_output_1_loss: 0.2563 - val_loss: 14.1693 - val_yolo_output_0_loss: 10.2656 - val_yolo_output_1_loss: 0.2156 - lr: 1.0000e-10\n",
      "Epoch 99/100\n",
      "166/166 [==============================] - ETA: 0s - loss: 4.1269 - yolo_output_0_loss: 0.1823 - yolo_output_1_loss: 0.2565\n",
      "Epoch 99: saving model to ./checkpointsTiny\\train_99.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1269 - yolo_output_0_loss: 0.1823 - yolo_output_1_loss: 0.2565 - val_loss: 14.1747 - val_yolo_output_0_loss: 10.2711 - val_yolo_output_1_loss: 0.2156 - lr: 1.0000e-10\n",
      "Epoch 100/100\n",
      "165/166 [============================>.] - ETA: 0s - loss: 4.1233 - yolo_output_0_loss: 0.1784 - yolo_output_1_loss: 0.2569\n",
      "Epoch 100: saving model to ./checkpointsTiny\\train_100.tf\n",
      "166/166 [==============================] - 8s 50ms/step - loss: 4.1233 - yolo_output_0_loss: 0.1784 - yolo_output_1_loss: 0.2569 - val_loss: 14.1786 - val_yolo_output_0_loss: 10.2749 - val_yolo_output_1_loss: 0.2156 - lr: 1.0000e-10\n"
     ]
    }
   ],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "93ef35a1-2f1d-4952-b6bd-9874f5216099",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x2aa88189090>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = YoloTiny(training=False)\n",
    "model.load_weights(\"./checkpointsTiny/train_100.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "29cfce06-940f-49a1-bfd3-013d2866ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tfds.load(\"emergency_dataset\", split=\"val\")\n",
    "ds = ds.batch(1)\n",
    "ds = ds.shuffle(1000)\n",
    "ds = ds.take(1)\n",
    "im = 1\n",
    "for e in ds:\n",
    "    im = e['image']\n",
    "imraw = im\n",
    "im = transform_images(im, 416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ba4e143-3bfd-46a8-9f31-1be9c097165b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01db601-ece0-4373-921e-faf9ea868db8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "926654a2-d154-4d9e-bdc2-a01650059d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_tflite(inpath, outpath):\n",
    "    model = YoloTiny(size=SIZE)\n",
    "    model.load_weights(inpath)\n",
    "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "    converter.experimental_new_converter = True\n",
    "    converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float16]\n",
    "    tflite_model = converter.convert()\n",
    "    f = open(outpath, 'wb')\n",
    "    f.write(tflite_model)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b914599-447e-4f66-af0d-e2257cb10f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "export_tflite(\"./checkpointsTiny/train_100.tf\", \"./models/yoloTiny.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7229cd7c-b869-442e-b1ad-cb0b0fca6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_image(model_path, img_path):\n",
    "    interpreter = tf.lite.Interpreter(model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    imRaw = cv2.imread(img_path)\n",
    "    im = cv2.cvtColor(imRaw, cv2.COLOR_BGR2RGB)\n",
    "    im = tf.convert_to_tensor(im)\n",
    "    im = tf.expand_dims(im, 0)\n",
    "    im = transform_images(im, 416)\n",
    "    \n",
    "    interpreter.set_tensor(input_details[0]['index'], im)\n",
    "    interpreter.invoke()\n",
    "    boxes = interpreter.get_tensor(output_details[2]['index'])\n",
    "    scores = interpreter.get_tensor(output_details[3]['index'])\n",
    "    classes = interpreter.get_tensor(output_details[0]['index'])\n",
    "    nums = interpreter.get_tensor(output_details[1]['index'])\n",
    "    imRaw = draw_outputs(imRaw, (boxes, scores, classes, nums))\n",
    "    cv2.imshow(\"a\", imRaw)\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "def detect_video(model_path, vid_path):\n",
    "    interpreter = tf.lite.Interpreter(model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    input_details = interpreter.get_input_details()\n",
    "    output_details = interpreter.get_output_details()\n",
    "    \n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    while cap.isOpened():\n",
    "        ret, frameRaw = cap.read()\n",
    "        frame = cv2.cvtColor(frameRaw, cv2.COLOR_BGR2RGB)\n",
    "        frame = tf.convert_to_tensor(frame)\n",
    "        frame = tf.expand_dims(frame, 0)\n",
    "        frame = transform_images(frame, 416)\n",
    "        \n",
    "        interpreter.set_tensor(input_details[0]['index'], frame)\n",
    "        interpreter.invoke()\n",
    "        boxes = interpreter.get_tensor(output_details[2]['index'])\n",
    "        scores = interpreter.get_tensor(output_details[3]['index'])\n",
    "        classes = interpreter.get_tensor(output_details[0]['index'])\n",
    "        nums = interpreter.get_tensor(output_details[1]['index'])\n",
    "        \n",
    "        frameRaw = draw_outputs(frameRaw, (boxes, scores, classes, nums))\n",
    "        cv2.imshow(\"a\", frameRaw)\n",
    "        cv2.waitKey(1)\n",
    "    \n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a8e29b-3d53-4ccf-9780-4a9e790a98f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_video(\"./models/yoloTiny.tflite\", \"./newData/inference/5.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7344314-6be5-4126-b8ed-00e310dff0ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091807.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091808.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091809.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091810.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091815.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091817.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091818.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091820.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091821.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091825.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091826.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091828.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091829.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091832.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091833.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091834.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091838.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091839.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091840.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091842.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091846.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091848.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091850.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091851.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091855.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091858.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091900.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091901.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091903.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091906.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091907.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091908.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091910.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091913.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091914.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091915.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091919.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091920.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091921.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091925.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091927.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091930.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091931.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091933.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091934.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091939.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091941.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091942.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091943.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091947.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091948.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091950.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091955.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091958.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_091959.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092001.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092005.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092007.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092008.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092010.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092013.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092015.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092019.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092020.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092022.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092026.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092027.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092030.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092033.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092035.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092037.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092038.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092042.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092045.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092054.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092059.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092102.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092106.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092107.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092109.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092110.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092115.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092117.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092120.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092122.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092126.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092128.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092129.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092135.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092137.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092141.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092144.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092148.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092149.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092152.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092156.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092157.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092201.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092203.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092206.txt\"\n",
      "  a = np.loadtxt(labelpath)\n",
      "C:\\Users\\stack\\AppData\\Local\\Temp\\ipykernel_16844\\3180385629.py:11: UserWarning: loadtxt: Empty input file: \"/Users/stack/Downloads/lbls\\IMG_20220403_092208.txt\"\n",
      "  a = np.loadtxt(labelpath)\n"
     ]
    }
   ],
   "source": [
    "i = 1197\n",
    "for filename in os.listdir(\"/Users/stack/Downloads/imgs/\"):\n",
    "    impath = os.path.join(\"/Users/stack/Downloads/imgs/\", filename)\n",
    "    labelfilename = filename[:-4] + '.txt'\n",
    "    labelpath = os.path.join(\"/Users/stack/Downloads/lbls\", labelfilename)\n",
    "    im = cv2.imread(impath)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    im = cv2.cvtColor(im, cv2.COLOR_GRAY2BGR)\n",
    "    im = cv2.resize(im, (512, 512))\n",
    "    cv2.imwrite(os.path.join(\"/Users/stack/Documents/warudo/yolo/newData/images\", str(i) + \".jpg\"), im)\n",
    "    a = np.loadtxt(labelpath)\n",
    "    a = np.reshape(a, (-1, 5))\n",
    "    for k in range(100 - a.shape[0]):\n",
    "        a = np.concatenate((a, np.array([[0.0, 0.0, 0.0, 0.0, 0.0]])), axis=0)\n",
    "    np.savetxt((os.path.join(\"/Users/stack/Documents/warudo/yolo/newData/labels\", str(i) + \".txt\")), a)\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba53c8d-0bcc-495e-a340-e6784f7cc184",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
