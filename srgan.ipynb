{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d10c2f-0c9c-4eef-9285-be8d90e83d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Flatten, Dense, LeakyReLU, PReLU, Add, Input, Lambda\n",
    "from tensorflow.keras.activations import sigmoid\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, LambdaCallback\n",
    "import tensorflow.keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053aed24-622f-425f-86cd-05f247ddb6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCHSIZE = 10\n",
    "NUMIMAGES = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27d66e1b-4819-44a1-8cf7-a6c7f70e00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, path, batch_size=BATCHSIZE):\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.idx = 1\n",
    "    \n",
    "    def reset(self):\n",
    "        self.idx = 0\n",
    "    \n",
    "    def get_next(self, num_blurs=1):\n",
    "        impath = os.path.join(self.path, str(self.idx).zfill(4) + \".jpg\")\n",
    "        \n",
    "        hr_img = tf.io.read_file(impath)\n",
    "        hr_img = tf.image.decode_image(hr_img)\n",
    "        hr_img = tf.image.convert_image_dtype(hr_img, tf.float32)\n",
    "        hr_img = tf.image.resize(hr_img, (416, 416))\n",
    "        \n",
    "        #lr_img = self.blur(hr_img, num_blurs)\n",
    "        lr_img = self.downscale(hr_img)\n",
    "        \n",
    "        self.idx += 1\n",
    "        return hr_img, lr_img\n",
    "    \n",
    "    def get_next_batch(self, num_blurs=1):\n",
    "        hrs = []\n",
    "        lrs = []\n",
    "        for _ in range(self.batch_size):\n",
    "            (hr, lr) = self.get_next(num_blurs)\n",
    "            hrs.append(tf.expand_dims(hr, 0))\n",
    "            lrs.append(tf.expand_dims(lr, 0))\n",
    "        hrs = tf.concat(hrs, 0)\n",
    "        lrs = tf.concat(lrs, 0)\n",
    "        return hrs, lrs\n",
    "    \n",
    "    def __call__(self):\n",
    "        yield self.get_next()\n",
    "    \n",
    "    def blur(self, img, n=1):\n",
    "        img = tf.identity(img)\n",
    "        img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "        \n",
    "        img = tf.transpose(img, perm=[2,0,1])\n",
    "        img = tf.expand_dims(img, -1)\n",
    "        \n",
    "        kernel = tf.constant(np.array([[1,2,1], [2,4,2], [1,2,1]]), dtype=tf.float32)\n",
    "        kernel = tf.expand_dims(kernel, -1)\n",
    "        kernel = tf.expand_dims(kernel, -1)\n",
    "        \n",
    "        for _ in range(n):\n",
    "            img = tf.nn.conv2d(img, kernel, strides=[1,1,1,1], padding='SAME') / (16)\n",
    "        img = tf.transpose(img, perm=[3,1,2,0])\n",
    "        img = tf.squeeze(img, 0)\n",
    "        return img\n",
    "    \n",
    "    def downscale(self, img):\n",
    "        return tf.image.resize(img, (104, 104))\n",
    "\n",
    "def show_hrlr(pair):\n",
    "    (hr, lr) = pair\n",
    "    if len(hr.shape) == 4:\n",
    "        hr = tf.squeeze(hr, 0)\n",
    "        lr = tf.squeeze(lr, 0)\n",
    "    (hr, lr) = dl.get_next(50)\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.imshow(hr)\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.imshow(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bc147340-7250-4ed1-8cef-e1cecb9ff31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResBlock(x):\n",
    "    skip = x\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = Add()([skip, x])\n",
    "    return x\n",
    "\n",
    "def PixelShuffle(x):\n",
    "    x = Conv2D(filters=256, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = Lambda(lambda x : tf.nn.depth_to_space(x, 2))(x)\n",
    "    x = PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
    "    return x\n",
    "\n",
    "def Generator():\n",
    "    x = x_input = Input((104, 104, 3))\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=9, strides=1, padding=\"same\")(x)\n",
    "    x = x_skip = PReLU(alpha_initializer=\"zeros\", alpha_regularizer=None, alpha_constraint=None, shared_axes=[1,2])(x)\n",
    "    \n",
    "    for _ in range(16):\n",
    "        x = ResBlock(x)\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = Add()([x_skip, x])\n",
    "    \n",
    "    for _ in range(2):\n",
    "        x = PixelShuffle(x)\n",
    "    \n",
    "    x = Conv2D(filters=3, kernel_size=9, strides=1, padding=\"same\")(x)\n",
    "    \n",
    "    return Model(inputs=x_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "693126f2-fd90-43b4-91c9-9d8f644beeb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlock(x, filters, strides):\n",
    "    x = Conv2D(filters=filters, kernel_size=3, strides=strides, padding=\"same\")(x)\n",
    "    x = BatchNormalization(momentum=0.5)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    return x\n",
    "\n",
    "def Discriminator():\n",
    "    x = x_input = Input((416, 416, 3))\n",
    "    \n",
    "    x = Conv2D(filters=64, kernel_size=3, strides=1, padding=\"same\")(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    \n",
    "    x = ConvBlock(x, filters=64, strides=2)\n",
    "    x = ConvBlock(x, filters=128, strides=1)\n",
    "    x = ConvBlock(x, filters=128, strides=2)\n",
    "    x = ConvBlock(x, filters=256, strides=1)\n",
    "    x = ConvBlock(x, filters=256, strides=2)\n",
    "    x = ConvBlock(x, filters=512, strides=1)\n",
    "    x = ConvBlock(x, filters=512, strides=2)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(units=1024)(x)\n",
    "    x = LeakyReLU(alpha=0.2)(x)\n",
    "    x = Dense(1)(x)\n",
    "    x = sigmoid(x)\n",
    "    \n",
    "    return Model(inputs=x_input, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cb53d988-ed5f-48e6-8e73-3c530b39bdc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(Model):\n",
    "    def __init__(self):\n",
    "        super(GAN, self).__init__()\n",
    "        \n",
    "        self.G = Generator()\n",
    "        self.D = Discriminator()\n",
    "        \n",
    "        self.vgg = VGG19(include_top=False, weights=\"imagenet\", input_shape=(416,416,3))\n",
    "        self.vgg.trainable = False\n",
    "        for layer in self.vgg.layers:\n",
    "            layer.trainable = False\n",
    "        self.vgg = Model(inputs=self.vgg.input, outputs=self.vgg.get_layer(\"block5_conv4\").output)\n",
    "    \n",
    "    def compile(self, content_loss, adversarial_loss, gen_optimizer, disc_optimizer):\n",
    "        super(GAN, self).compile()\n",
    "        self.content_loss = content_loss\n",
    "        self.adversarial_loss = adversarial_loss\n",
    "        self.gen_optimizer = gen_optimizer\n",
    "        self.disc_optimizer = disc_optimizer\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        (hr, lr) = data\n",
    "        \n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            sr = self.G(lr)\n",
    "            discriminator_output_fake = self.D(sr)\n",
    "            discriminator_output_real = self.D(hr)\n",
    "            gen_loss = self.content_loss(self.vgg, hr, sr)\n",
    "            disc_loss = self.adversarial_loss(discriminator_output_fake, discriminator_output_real)\n",
    "        \n",
    "        gen_grads = gen_tape.gradient(gen_loss, self.G.trainable_weights)\n",
    "        disc_grads = disc_tape.gradient(disc_loss, self.D.trainable_weights)\n",
    "        \n",
    "        self.gen_optimizer.apply_gradients(zip(gen_grads, self.G.trainable_weights))\n",
    "        self.disc_optimizer.apply_gradients(zip(disc_grads, self.D.trainable_weights))\n",
    "        \n",
    "        return {\"content_loss\" : gen_loss, \"adversarial_loss\" : disc_loss}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea755131-b2b5-4eed-aa20-b39bcce3a5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(vgg, hr, sr):\n",
    "    loss = K.mean(K.square(vgg(hr) - vgg(sr)))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "523a0e0e-bb44-4092-ac0c-a62ffd5e1404",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    dl = DataLoader(path=\"/Users/anonymous/Documents/warudo/datasets/coco_val2017/\")\n",
    "    gan = GAN()\n",
    "    gan.compile(\n",
    "        content_loss=content_loss,\n",
    "        adversarial_loss=BinaryCrossentropy(),\n",
    "        gen_optimizer=Adam(0.003),\n",
    "        disc_optimizer=Adam(0.003)\n",
    "    )\n",
    "    num_batches = NUMIMAGES / BATCHSIZE\n",
    "    for _ in num_batches:\n",
    "        gan.train_step(dl.get_next_batch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fcc36f5-71c8-4022-9ffd-5cc9831fe66d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
